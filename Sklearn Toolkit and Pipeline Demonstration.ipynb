{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Toolkit and Pipeline Demonstation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document aims to give a brief tutorial to share some of the methods I learned during Professor Andrew Delong's course: COMP6321 (Machine Learning)\n",
    "\n",
    "* Part 1 — Default Models, Dummy Classifiers, and Cross Validation\n",
    "* Part 2 — Hyperparmeter tuning using grid and random search\n",
    "* Part 3 — Sklearn Pipeline\n",
    "* Part 4 — Custom Classifiers and Estimators\n",
    "\n",
    "To use: get data from: https://www.kaggle.com/c/ashrae-energy-prediction/data. Download all files and put in a folder called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import scipy\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import sklearn.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23b5e322b5c4f1c86cc2998d96c75d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded data:\n",
      "\tbuilding_metadata\n",
      "\tsample_submission\n",
      "\ttest\n",
      "\ttrain\n",
      "\tweather_test\n",
      "\tweather_train\n"
     ]
    }
   ],
   "source": [
    "# Read in all csv files saved in the data folder\n",
    "files = glob.glob(\"data/*.csv\")\n",
    "data = {}\n",
    "for f in tqdm(files):\n",
    "    name = f.split('\\\\')[1].split('.')[0]\n",
    "    data[name] = pd.read_csv(f)\n",
    "\n",
    "print('Downloaded data:')\n",
    "for f in files: print('\\t{}'.format(f.split('\\\\')[1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/mtl_buildings.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration, the \"problem\" has been reimagined to be a classification problem. This document aims to answer: if you have a year's worth of energy use, building area, and climate conditions, can we estimate the primary building use type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggrigate data by building\n",
    "train_set = data['train'].groupby('building_id')['meter_reading'].sum().to_frame().reset_index()\n",
    "\n",
    "# Organize Weather Data by min, max, mean\n",
    "weather = data['weather_train'][['site_id', 'timestamp', 'air_temperature']]\n",
    "weather_max = weather.groupby('site_id')['air_temperature'].max().to_frame().rename(columns={'air_temperature': 'temp_max'})\n",
    "weather_mean = weather.groupby('site_id')['air_temperature'].mean().to_frame().rename(columns={'air_temperature': 'temp_mean'})\n",
    "weather_min = weather.groupby('site_id')['air_temperature'].min().to_frame().rename(columns={'air_temperature': 'temp_min'})\n",
    "weather = pd.concat([weather_max, weather_mean, weather_min], axis=1).reset_index()\n",
    "\n",
    "# Exclude year and floors due to excess missing data\n",
    "building = data['building_metadata'][['site_id', 'building_id', 'primary_use', 'square_feet']]\n",
    "\n",
    "#Merge Data\n",
    "merged_data = pd.merge(train_set, building, on='building_id')\n",
    "merged_data = pd.merge(merged_data, weather, on=['site_id'])\n",
    "merged_data = merged_data[['primary_use', 'square_feet', 'meter_reading', 'temp_max', 'temp_mean', 'temp_min']]\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_data['primary_use'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the models below to work, the low-frequency sets were excluded from the test set. Perhaps the errors associated with including them could be resolved in a future revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_type_count = merged_data['primary_use'].value_counts() # Get value counts\n",
    "remove = use_type_count[use_type_count<10].index.tolist() # Get list of building types with less than 10 representations\n",
    "trimmed = merged_data[~merged_data['primary_use'].isin(remove)] # Remove those buildings from datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Part 1 &mdash; Default Models, Dummy Classifiers, and Cross Validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sklearn_header.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic commands associated with sklearn estimators:\n",
    "```python\n",
    "estimator.fit(X_train, y_train)\n",
    "estimator.predict(X_test)\n",
    "estimator.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "Sklearn Transformers:\n",
    "```python\n",
    "transformer.fit(X)\n",
    "transformer.trasnform(X)\n",
    "transformer.score(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y features\n",
    "included_features = ['meter_reading', 'square_feet', 'temp_max', 'temp_mean', 'temp_min']\n",
    "X = trimmed[included_features]\n",
    "y = trimmed[['primary_use']].values.ravel()\n",
    "\n",
    "#Split train test using the sklearn train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn toolbox offers a variety of dummy models, which employ simple strategies to baseline against your models. In the example below, we will compare an unoptimized decision tree with the simple strategy of guessing the most common building type.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline \n",
    "# dum = DummyClassifier(strategy='most_frequent')\n",
    "# dum.fit(X_train,y_train)\n",
    "\n",
    "# print('The DummyClassifier has a score of\\n {:0.1f}% training set\\n {:0.1f}% testing set'.format(\n",
    "#     dum.score(X_train, y_train)*100, dum.score(X_test, y_test)*100\n",
    "# ))\n",
    "\n",
    "# Decision tree using default hyperparameters\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "print('')\n",
    "print('The DecisionTreeClassifier has a score of\\n {:0.1f}% training set\\n {:0.1f}% testing set'.format(\n",
    "    dt.score(X_train, y_train)*100, dt.score(X_test, y_test)*100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, we need to tune the hyperparameters of the model to avoid overfitting and make the model more robust. For example, one parameter in a decision tree is the max depth. Therefore, we could suspect that our trained decision tree is too deep, hence the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth of decision tree when max_depth is not trained\n",
    "dt.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(2,10):\n",
    "    print('for max_depth={}:  score on test data:{:0.1%}'.format(\n",
    "        depth, DecisionTreeClassifier(max_depth=depth, random_state=0).fit(X_train, y_train).score(X_test, y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on video: https://www.youtube.com/watch?v=8gLewErTU24\n",
    "def plot_conf_matix(y_true, y_pred, plot_title=None):\n",
    "    \"\"\"\n",
    "    Creates heatmap using \n",
    "    \"\"\"\n",
    "    labels = sklearn.utils.multiclass.unique_labels(np.hstack((y_true,y_pred)))\n",
    "    column = [f'{label}' for label in labels]\n",
    "    indicies = column\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize=None)    \n",
    "    table = pd.DataFrame(cm, columns=column, index=indicies)\n",
    "    sns.heatmap(table, annot=True, fmt='d', cmap='viridis')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "y_pred = dt.fit(X_train, y_train).predict(X_test)\n",
    "plot_conf_matix(y_test, y_pred, plot_title='Decision tree classifier');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: excerpt from lab 7 from Professor Andrew Delong's course: COMP6321 (Machine Learning), Concordia University 2021\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "As a rule, data marked as a \"test set\" should ALMOST NEVER be used for training, or even for model selection. All modeling choices (parameters, best model) must be made based on training data, ONLY. Otherwise you will very likely fool yourself, or others, into thinking your system will perform well on held-out data when it will not. \n",
    "\n",
    "\"Peeking\" at the test data, directly or indirectly, or even measuring the performance on test data too often, is even considered cheating. In fact, at least <a href=\"https://www.cio.com/article/2935233/baidu-fires-researcher-involved-in-ai-contest-flap.html\">one well-known machine learning scientist was <b>fired from his job</b></a> for trying to tune hyperparameters directly to the test data.\n",
    "\n",
    "\n",
    "***K*-fold cross validation** is a specific procedure for estimating held-out performance using only the training set. It creates *K* different (training, validation) splits and then averaging the validation performance measured on each one. (Beware that scikit-learn's [desciption of cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold) sometimes refers to the *K* individual validation sets as \"test sets\" so this can be confusing since they are not really validation sets.) The *K*-fold cross validation procedure is depicted below. When there are *K* splits the result is *K* different performance estimates, one for each of the held-out folds.\n",
    "<img src=\"img/grid_search_cross_validation.png\" width=\"550\">\n",
    "\n",
    "(Image source: https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "Note that the \"test data\" depicted above is not needed for the cross validation procedure itself, and is only used as an (optional) final performance evaluation, after the model selection procedure.\n",
    "\n",
    "Use the **[sklearn.metrics.accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)** function or, equivalently, the **[score](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.score)** method of your *DecisionTreeClassifier* to compute the training and testing accuracies.\n",
    "\n",
    "Use the **[sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)** function to do the cross validation. It will return an array of *K* values, so you need to average them to get an overall estimate.\n",
    "\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time based data you can also use a time series split rather than a k-fold split to better simulate time series data.\n",
    "\n",
    "<img src=\"img/kFold.png\" width=\"550\">\n",
    "<img src=\"img/TimeSeries.png\" width=\"550\">\n",
    "\n",
    "image source(https://datascience.stackexchange.com/questions/41378/how-to-apply-stacking-cross-validation-for-time-series-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using k-fold cross validation on test data\n",
    "\n",
    "# Create DT classifier using optimized max depth (found previously)\n",
    "dt = DecisionTreeClassifier(random_state=1, max_depth=7).fit(X_train, y_train)\n",
    "\n",
    "# Print score on training and testing set\n",
    "print('The training accuracy is: {:.1%}'.format(dt.score(X_train, y_train)))\n",
    "print('The testing accuracy is: {:.1%}'.format(dt.score(X_test, y_test)))\n",
    "\n",
    "# Loop through range of train test split to observe performance.\n",
    "for i in range(2,7):\n",
    "    accuracy = sklearn.model_selection.cross_val_score(dt, X_train, y_train, cv=i)\n",
    "    print('held-out accuracy ({}-fold): {:.1%}'.format(i, np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can conclude that using the cross validation give us a reliable esitmate of how our model with act on our testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Part 2 &mdash; Hyperparmeter tuning using grid search and random search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = False #Toggle to false to access pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/gridsearchvsrandomsearch.png\" width=\"550\">\n",
    "\n",
    "image source (https://blog.usejournal.com/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85?gi=f8c3537f6b61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sklearn_dt.png\">\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision%20tree#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up grid for grid search\n",
    "grid = {\n",
    "    'max_depth': range(1,100),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "# Use the sklearn grid search\n",
    "gs_dt = sklearn.model_selection.GridSearchCV(\n",
    "    estimator=dt, \n",
    "    param_grid=grid,\n",
    "    n_jobs=12, # Based on the number of threads in your cpu core, n=-1 means use all cpu threads\n",
    "    cv=5, # Cross validation split \n",
    "    verbose=1 # Higher means more updates \n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Print\n",
    "pd.DataFrame(gs_dt.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sklearn_rf.png\">\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Set up distributions. The search will sample randomly from all the possible variations\n",
    "dist = {\n",
    "    'max_depth': range(1, 100),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "#Random search \n",
    "cv_rf = sklearn.model_selection.RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=dist,\n",
    "    verbose=1,\n",
    "    cv=5, n_iter=500, n_jobs=12\n",
    ").fit(X_train, y_train)\n",
    "pd.DataFrame(cv_rf.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sklearn_svc.png\">\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    svc = SVC()\n",
    "    # You can also add in distribution rather than ranges of numbers\n",
    "    dist = {\n",
    "        'C': scipy.stats.uniform(1, 1000),\n",
    "        'gamma': scipy.stats.reciprocal(1, 1000)\n",
    "    }\n",
    "\n",
    "    cv_svc = sklearn.model_selection.RandomizedSearchCV(\n",
    "        estimator=svc,\n",
    "        param_distributions=dist,\n",
    "        verbose=1,\n",
    "        cv=5, n_iter=500, n_jobs=12\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    with open('models/cv_svc.pkl', 'wb') as f:\n",
    "        pkl.dump(cv_svc, f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    with open('models/cv_svc.pkl', 'rb') as f:\n",
    "        cv_svc = pkl.load(f)\n",
    "\n",
    "pd.DataFrame(cv_svc.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [gs_dt, cv_rf, cv_svc]\n",
    "names = ['dt', 'rf', 'svc']\n",
    "\n",
    "\n",
    "print('The results are:')\n",
    "\n",
    "print('{}:\\ttrain acc:{:0.1%} \\t test acc:{:0.1%}'.format(\n",
    "    'dum', dum.score(X_train, y_train), dum.score(X_test, y_test)\n",
    "))\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    model.best_estimator_.fit(X_train, y_train)\n",
    "    print('{}:\\ttrain acc:{:0.1%} \\t test acc:{:0.1%}'.format(\n",
    "        name, model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Part 3 &mdash; Sklearn Pipeline*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pipeline.jpg\" width=\"500\" align=\"left\">\n",
    "<img src=\"img/pipeline_flow_chart.svg\" width=\"700\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines can be created using the sklearn pipeline function\n",
    "svcs = sklearn.pipeline.Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model',  SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function provides better visualization of the pipeline\n",
    "sklearn.set_config(display='diagram')\n",
    "svcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prints all available paramters that we can \"tune\" durring the random search\n",
    "# As shown, you can still access all paramters within sklearn style estimators\n",
    "def print_param_names(estimator):\n",
    "    for name in estimator.get_params():\n",
    "        print(name)\n",
    "\n",
    "print_param_names(svcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    dist = {\n",
    "        'model__C': scipy.stats.reciprocal(1, 100),\n",
    "        'model__gamma': scipy.stats.reciprocal(1, 100),\n",
    "    }\n",
    "    cv_svcs = sklearn.model_selection.RandomizedSearchCV(\n",
    "        estimator=svcs,\n",
    "        param_distributions=dist,\n",
    "        verbose=1,\n",
    "        cv=5, n_iter=500, n_jobs=12\n",
    "    ).fit(X_train, y_train)\n",
    "    pd.DataFrame(cv_svcs.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "    with open('models/cv_svcs.pkl', 'wb') as f:\n",
    "        pkl.dump(cv_svcs, f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    with open('models/cv_svcs.pkl', 'rb') as f:\n",
    "        cv_svcs = pkl.load(f)\n",
    "\n",
    "pd.DataFrame(cv_svcs.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_svcs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [gs_dt, cv_rf, cv_svc, cv_svcs]\n",
    "names = ['dt', 'rf', 'svc', 'svcs']\n",
    "\n",
    "\n",
    "print('The results are:')\n",
    "\n",
    "print('{}:\\ttrain acc:{:0.1%} \\t test acc:{:0.1%}'.format(\n",
    "    'dum', dum.score(X_train, y_train), dum.score(X_test, y_test)\n",
    "))\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    model.best_estimator_.fit(X_train, y_train)\n",
    "    print('{}:\\ttrain acc:{:0.1%} \\t test acc:{:0.1%}'.format(\n",
    "        name, model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Part 4 &mdash; Custom Classifiers and Estimators*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we will write a custom transformer and a custom estimator. You may be thinking up until now that this looks good, but you require special preprocessing and models based on your expertise in the data, so these pre-made sklearn models will not work. There is a way to integrate your particular needs into a sklearn style model. The advantage to this is that you can rapidly compare your models to a vast library of these pre-made models, and you can take advantage of the sklearn tools, such as random search\n",
    "\n",
    "To see a more formal example you can look at the source code of the standard scaler: https://github.com/automl/paramsklearn/blob/master/ParamSklearn/implementations/StandardScaler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the transformer below, we image a situation where we are unsure if the weather inputs are acually useful. Perhaps what would be better if we just designate the location, and we allow the models simply to understand the some buildings are in the same location, rather than trying to derive mening from the max, min, and mean weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_processer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This custom transformer will any of the following depending on the input\n",
    "        1. Do nothing to the input features\n",
    "        2. Normalize all the input features base on an sklearn style pre-processer\n",
    "        3. Encode the categorized weather data into a unique encoder using a sklearn style encoder\n",
    "        4. Both encode weather data and normalize non-weather data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalizer=None, encoder=None):\n",
    "        \"\"\"\n",
    "        This function is reqired and can be used for the transfomer inputs.\n",
    "        ***Important note: make sure your class names are the same as your input names,\n",
    "            otherwise the random search will not work.\n",
    "        \"\"\"\n",
    "        self.normalizer = normalizer\n",
    "        self.encoder = encoder\n",
    "        return None\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"\n",
    "        This function is reqired\n",
    "        \"\"\"\n",
    "        if self.encoder is not None:\n",
    "            x_left = x.iloc[:,0:2]\n",
    "            x_right = (x.iloc[:, 2] * x.iloc[:, 3] * x.iloc[:, 4]).to_frame()\n",
    "            self.encoder.fit(x_right)\n",
    "            if self.normalizer is not None:\n",
    "                self.normalizer.fit(x_left)\n",
    "        elif self.normalizer is not None:          \n",
    "            self.normalizer.fit(x)\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        \"\"\"\n",
    "        This function is reqired\n",
    "        \"\"\"\n",
    "        if self.encoder is not None:\n",
    "            x_left = x.iloc[:,0:2]\n",
    "            x_right = (x.iloc[:, 2] * x.iloc[:, 3] * x.iloc[:, 4]).to_frame()\n",
    "            x_right = pd.DataFrame(self.encoder.transform(x_right))\n",
    "            if self.normalizer is not None:\n",
    "                x_left = pd.DataFrame(self.normalizer.transform(x_left) )\n",
    "            x_left.reset_index(drop=True, inplace=True)\n",
    "            x_right.reset_index(drop=True, inplace=True)\n",
    "            return pd.concat([x_left, x_right], ignore_index=True, axis=1)\n",
    "        elif self.normalizer is not None:          \n",
    "            return pd.DataFrame(self.normalizer.transform(x))\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "    def inverse_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        If you wanted you can create an inverse transform \n",
    "        but it is not requred for the sklearn pipeline.\n",
    "        \"\"\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pre_processer(\n",
    "#     normalizer=StandardScaler(),\n",
    "#     encoder=OrdinalEncoder()\n",
    ")\n",
    "\n",
    "pre.fit_transform(X_train)\n",
    "# Note, fit_transform is not a function that we wrote, but we can still take \n",
    "# advantage of it becuase it is an sklearn style classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcspecialboi = sklearn.pipeline.Pipeline(steps=[\n",
    "    ('pre_processing', pre_processer()),\n",
    "    ('model',  sklearn.svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_param_names(svcspecialboi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    dist = {\n",
    "        'pre_processing__encoder': [None, OrdinalEncoder()],\n",
    "        'pre_processing__normalizer': [None, StandardScaler()],\n",
    "        'model__C': scipy.stats.reciprocal(1, 100),\n",
    "        'model__gamma': scipy.stats.reciprocal(1, 100)\n",
    "    }\n",
    "\n",
    "    cv_svcspecialboi = sklearn.model_selection.RandomizedSearchCV(\n",
    "        estimator=svcspecialboi,\n",
    "        param_distributions=dist,\n",
    "        verbose=1,\n",
    "        cv=5, n_iter=500, n_jobs=12\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    with open('models/cv_svcspecialboi.pkl', 'wb') as f:\n",
    "        pkl.dump(cv_svcspecialboi, f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    with open('models/cv_svcspecialboi.pkl', 'rb') as f:\n",
    "        cv_svcspecialboi = pkl.load(f)\n",
    "        \n",
    "pd.DataFrame(cv_svcspecialboi.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a sklearn estimator. For more information see the sklearn documentation:\n",
    "https://scikit-learn.org/stable/developers/develop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_size(guess_num, length):\n",
    "        if guess_num > length:\n",
    "            raise ValueError(\n",
    "                'The number needs to be less than the unique values of the training set ({})'.format(length))\n",
    "\n",
    "class silly_estimator(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    This estimator is not acually that usefull. its only purpose is to show a relatively simple predictor.\n",
    "    It simply takes a list of all unique y outputs and selects which one to use base on the guess_number\n",
    "    inputer hyperparameter. It does not do anything with the x inputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, guess_number=0):\n",
    "        '''\n",
    "        Reqired function. This allows class hyperparameter inputs\n",
    "        ***Important note: make sure your class names are the same as your input names,\n",
    "            otherwise the random search will not work.\n",
    "        '''\n",
    "        self.guess_number = guess_number\n",
    "        return None\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.options = np.unique(np.array(y))\n",
    "        self.length = len(self.options)\n",
    "        check_size(self.guess_number, self.length)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        length, _ = x.shape\n",
    "        guess = self.options[self.guess_number]\n",
    "        return np.full((length,), guess).tolist()\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        \"\"\"\n",
    "        score is reqired so the random search knows what is the best estimator\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return sklearn.metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly = silly_estimator(guess_number=0)\n",
    "silly.fit(X_train, y_train).predict(X_test)[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    grid = {\n",
    "        'guess_number': range(12),\n",
    "    }\n",
    "    gs_silly = sklearn.model_selection.GridSearchCV(\n",
    "        estimator=silly, \n",
    "        param_grid=grid,\n",
    "        n_jobs=12,\n",
    "        cv=5,\n",
    "        verbose=1 \n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    with open('models/gs_silly.pkl', 'wb') as f:\n",
    "        pkl.dump(gs_silly, f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    with open('models/gs_silly.pkl', 'rb') as f:\n",
    "        gs_silly = pkl.load(f)\n",
    "\n",
    "pd.DataFrame(gs_silly.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_model(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    This custom predictor takes up to 3 sklearn classifiers, fits them all to the training data and predicts\n",
    "    the most common prediction between the three predictions\n",
    "    \"\"\"\n",
    "    def __init__(self, model1=None, model2=None, model3=None):\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        if model1 is None:\n",
    "            raise ValueError(\"Model1 is not defined\")\n",
    "        if model2 is None and self.model3 is not None:\n",
    "            raise ValueError(\"Define models in order\")\n",
    "        return None\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.model1.fit(x, y)\n",
    "        if self.model2 is not None:\n",
    "            self.model2.fit(x, y)\n",
    "        if self.model3 is not None:\n",
    "            self.model3.fit(x, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        estimate_model1 = self.model1.predict(x).reshape(-1,1)\n",
    "        estimate = estimate_model1\n",
    "        if self.model2 is not None:\n",
    "            estimate_model2 = self.model2.predict(x).reshape(-1,1)\n",
    "            estimate = np.hstack([estimate_model1, estimate_model2])\n",
    "        if self.model3 is not None:\n",
    "            estimate_model3 = self.model3.predict(x).reshape(-1,1)\n",
    "            estimate = np.hstack([estimate_model1, estimate_model2, estimate_model3])\n",
    "        y_pred, _ = scipy.stats.mode(estimate, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        return sklearn.metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_predictor = sklearn.pipeline.Pipeline(steps=[\n",
    "    ('pre_processing', pre_processer()),\n",
    "    ('model',  multi_model(\n",
    "        model1=DecisionTreeClassifier(),\n",
    "        model2=RandomForestClassifier(),\n",
    "        model3=SVC()\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function provides better visualization of the pipeline\n",
    "sklearn.set_config(display='diagram')\n",
    "custom_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_param_names(custom_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "\n",
    "    dist = {\n",
    "        'pre_processing__encoder': [None, OrdinalEncoder()],\n",
    "        'pre_processing__normalizer': [None, sklearn.preprocessing.StandardScaler()],\n",
    "\n",
    "        'model__model1__max_depth': scipy.stats.reciprocal(1, 100),\n",
    "\n",
    "        'model__model2__max_depth': scipy.stats.reciprocal(1, 100),\n",
    "        'model__model2__max_features': ['sqrt', 'log2'],\n",
    "        'model__model2__bootstrap': [True, False],\n",
    "\n",
    "        'model__model3__C': scipy.stats.reciprocal(1, 100),\n",
    "        'model__model3__gamma': scipy.stats.reciprocal(1, 100)\n",
    "    }\n",
    "    cv_custom_predictor = sklearn.model_selection.RandomizedSearchCV(\n",
    "        estimator=custom_predictor,\n",
    "        param_distributions=dist,\n",
    "        verbose=2,\n",
    "        cv=5, n_iter=500, n_jobs=12\n",
    "    ).fit(X_train, y_train.ravel())\n",
    "    \n",
    "    \n",
    "    with open('models/cv_custom_predictor.pkl', 'wb') as f:\n",
    "        pkl.dump(cv_custom_predictor, f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    with open('models/cv_custom_predictor.pkl', 'rb') as f:\n",
    "        cv_custom_predictor = pkl.load(f)\n",
    "    \n",
    "pd.DataFrame(cv_custom_predictor.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [gs_dt, cv_rf, cv_svc, cv_svcs, gs_silly, cv_custom_predictor]\n",
    "names = ['dt', 'rf', 'svc', 'svcs', 'silly', 'cust']\n",
    "\n",
    "\n",
    "print('The results are:')\n",
    "\n",
    "print('{}:\\ttrain acc:{:0.1%} \\t test acc:{:0.1%}'.format(\n",
    "    'dum', dum.score(X_train, y_train), dum.score(X_test, y_test)\n",
    "))\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    model.best_estimator_.fit(X_train, y_train)\n",
    "    print('{}:\\ttrain acc:{:0.1%} \\t test acc:{:0.1%}'.format(\n",
    "        name, model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.set_config(display='diagram')\n",
    "cv_custom_predictor.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
